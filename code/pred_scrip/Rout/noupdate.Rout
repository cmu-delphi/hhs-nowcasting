
R version 4.4.0 (2024-04-24) -- "Puppy Cup"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> "
+ Scenario 2: No further hospitalizations recieved after Dec 1, 2021 
+ "
[1] "\nScenario 2: No further hospitalizations recieved after Dec 1, 2021 \n"
> 
> source("assets_noupdate/data_load.R")

Attaching package: ‘epiprocess’

The following object is masked from ‘package:stats’:

    filter


Attaching package: ‘lubridate’

The following objects are masked from ‘package:base’:

    date, intersect, setdiff, union


Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Rows: 47941871 Columns: 9
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr  (1): geo_value
dbl  (6): lag, value_covid, value_total, sum_covid, sum_total, weekly_in_ratio
date (2): issue_date, time_value

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 36836755 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr  (1): geo_value
dbl  (6): lag, value_covid, value_total, sum_covid, sum_total, weekly_out_ratio
date (3): issue_date, time_value, end

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 55578 Columns: 4
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr  (1): geo_value
dbl  (1): GT
date (2): time_value, issue_date

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Rows: 20980 Columns: 3
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr  (1): geo_value
dbl  (1): GT
date (1): time_value

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> source("assets_noupdate/unconstrained_state_level_big_lag.R")
> source("assets_noupdate/unconstrained_national_level_bl.R")
> 
> 
> 
> omi_start = as.Date("2021-11-30")
> end_date = as.Date("2023-08-01")
> gammas = signif(seq(0, 0.0625, length.out = 25), 3)
> alphas = signif(seq(0, 1, length.out = 51))
> 
> cadence = 30
> offset = 120
> vl = 2
> 
> state_model_coef = c()
> national_model_coef = c()
> 
> back_2 = c()
> val_frame = c()
> val_gamma = c()
> 
> 
> # Still need to iterate through all dates, with the exception of no retraining after
> # 30 days of beginning of start of omicron
> # NOTE: Still need to produce backcasts
> 
> for (d in seq(omi_start + 1, end_date, by = 1)) {
+   
+   # If less than 30 days after start, still retrain
+ 
+   if (d <= omi_start + 30) {
+     
+     # Train end is always the same in scenario 2
+     train_end = omi_start - vl * cadence
+     test_start = omi_start + 1
+     
+     version = as.Date(d, "1970-01-01")
+     
+     # state level val frame 
+     state_val_frame = state_produce_fv(gammas, train_end, version)
+     
+     # National level val frame 
+     national_val_frame = national_produce_fv(gammas, train_end, version)
+     
+     if (nrow(state_val_frame) == 0) {
+       
+       break
+       
+     }
+     
+     # Make sure test predictions are out of sample
+     stopifnot(state_val_frame$time_value <= as.Date(test_start, "1970-01-01"))
+     
+     
+     # Select FV gamma and retrain, both state-level and geo-pooled
+     state_val_gamma = state_val_frame %>%
+       group_by(geo_value, gamma) %>%
+       summarise(MAE = mean(abs(.resid))) %>%
+       mutate(Min = min(MAE)) %>%
+       filter(MAE == Min) %>%
+       select(geo_value, gamma)
+     
+     
+     national_gamma = national_val_frame %>%
+       group_by(gamma) %>%
+       summarise(MAE = mean(abs(.resid))) %>%
+       mutate(Min = min(MAE)) %>%
+       filter(MAE == Min) %>%
+       select(gamma)
+     
+     # Refit, this time using all the data, with `omi_start` as cutoff
+     # Becuase no future labels are made available to us
+     ## State level data
+     state_train = state_get_train_ar(omi_start, version) %>%
+       group_by(geo_value) %>%
+       merge(state_val_gamma, by = "geo_value")
+     
+     ## National level data
+     national_train = national_get_train_ar(omi_start, version) %>%
+       ungroup() %>%
+       mutate(ng = national_gamma$gamma)
+     
+     ## Refit, state-level and geo-pooled
+     state_selected_models = state_train %>%
+       group_by(geo_value) %>%
+       do(model = lm(GT ~ in_6 + in_13 + in_20 + out_6 + out_13 + out_20, 
+                     weights = exp(-gamma * backcast_lag) / max(exp(-gamma * backcast_lag)),
+                     data = .))
+     
+     national_selected_models = lm(GT ~ in_6 + in_13 + in_20 + out_6 + out_13 + out_20, 
+                     weights = exp(-ng * backcast_lag) / max(exp(-ng * backcast_lag)),
+                     data = national_train)
+     
+     
+     # After selection and retrain, store the models with `geo_value` and `issue_date`
+     # It is important to store the RETRAINED coefficents
+     state_selected_tmp = state_selected_models %>%
+       group_by(geo_value) %>%
+       group_modify(~ bind_rows(coef(.$model[[1]]))) %>%
+       mutate(issue_date = as.Date(version, "1970-01-01"))
+     
+     state_model_coef = rbind(state_model_coef, state_selected_tmp)
+     
+ 
+     
+     national_model_coef = rbind(national_model_coef, c(national_selected_models$coefficients, 
+       as.Date(version, "1970-01-01")))
+     
+     
+     
+     # After selection and retrain, store the models with `geo_value` and `issue_date`
+     # It is important to store the RETRAINED coefficents
+     state_selected_tmp = state_selected_models %>%
+       group_by(geo_value) %>%
+       group_modify(~ bind_rows(coef(.$model[[1]]))) %>%
+       mutate(issue_date = as.Date(version, "1970-01-01"))
+     
+     
+     
+     # Find alphas now
+     mixed_val_frame = alpha_fv(alphas, state_val_frame, national_val_frame, state_val_gamma, national_gamma)
+     opt_alpha = mixed_val_frame %>%
+       group_by(geo_value, alpha) %>%
+       summarise(MAE = mean(.resid)) %>%
+       mutate(Min = min(MAE)) %>%
+       filter(MAE == Min) %>%
+       rename(optimal = alpha) %>%
+       select(geo_value, optimal)
+     
+     
+     
+     state_test = state_get_test_backnow_raw(test_start, version)
+     national_test = national_get_test_backnow_raw(test_start, version)
+     
+     # If not test points at all, next date in test time
+     if (nrow(state_test) == 0) {
+       next
+     }
+     
+     # Another round of making sure out of sample
+     stopifnot(max(state_val_frame$time_value) <= min(state_test$time_value))
+     stopifnot(max(state_train$time_value) <= min(state_test$time_value))
+     
+     # Use inner_join to avoid problems in null data
+     # So that you don't actually predict training samples...
+     state_test = state_test %>%
+       group_by(geo_value) %>%
+       nest() %>%
+       inner_join(state_selected_models) %>%
+       verify(nrow(.) != 0)
+     
+     national_test = national_test %>%
+     mutate(
+       # Generate predictions with 60% prediction interval
+       preds_60 = {
+         pred_df = as.data.frame(predict(national_selected_models, newdata = national_test, interval = "prediction", level = 0.6))
+         names(pred_df)[names(pred_df) == "lwr"] = "lwr_60"
+         names(pred_df)[names(pred_df) == "upr"] = "upr_60"
+         names(pred_df)[names(pred_df) == "fit"] = "national_fit"
+         pred_df
+       },
+       # Generate predictions with 80% prediction interval
+       preds_80 = {
+         pred_df = as.data.frame(predict(national_selected_models, newdata = national_test, interval = "prediction", level = 0.8))
+         names(pred_df)[names(pred_df) == "lwr"] = "lwr_80"
+         names(pred_df)[names(pred_df) == "upr"] = "upr_80"
+         # No renaming to `state_fit` here as we will discard this fit
+         pred_df
+       }
+     ) %>%
+     unnest(c(preds_60, preds_80)) %>%
+     select(-fit) %>%  # Discarding the duplicate fit from the 80% prediction
+     mutate(resid = abs(national_fit - GT))
+     
+ 
+     state_Tested = state_test %>%
+       mutate(
+         preds_60 = map2(model, data, 
+                         ~{
+                           pred_df <- as.data.frame(predict(.x, newdata = .y, interval = "prediction", level = 0.6))
+                           names(pred_df)[names(pred_df) == "lwr"] <- "lwr_60"
+                           names(pred_df)[names(pred_df) == "upr"] <- "upr_60"
+                           names(pred_df)[names(pred_df) == "fit"] <- "state_fit"
+                           pred_df
+                         }),
+         preds_80 = map2(model, data, 
+                         ~{
+                           pred_df <- as.data.frame(predict(.x, newdata = .y, interval = "prediction", level = 0.8))
+                           names(pred_df)[names(pred_df) == "lwr"] <- "lwr_80"
+                           names(pred_df)[names(pred_df) == "upr"] <- "upr_80"
+                           names(pred_df)[names(pred_df) == "fit"] <- "fit_80"
+                           pred_df
+                         })
+       ) %>%
+       select(-model) %>%
+       unnest(cols = c(preds_60, preds_80, data)) %>%
+       select(-fit_80) %>%
+       mutate(
+         resid = abs(state_fit - GT)
+       )
+     Tested = state_Tested %>%
+       inner_join(national_Tested, by = c("geo_value", "time_value", "issue_date")) %>%
+       inner_join(opt_alpha, by = "geo_value") %>%
+       group_by(geo_value) %>%
+       mutate(mixed_pred = optimal * state_fit + (1 - optimal) * national_fit) %>%
+       mutate(staleness = as.numeric(time_value - omi_start))
+     
+     
+     back_2 = rbind(back_2, Tested)
+     
+   }
+   
+   else {
+     
+     # After 30 days, all signales considerd finalized. 
+     # Freeze models and just predict. 
+     
+     version = as.Date(d, "1970-01-01")
+     
+     print(as.Date(d, "1970-01-01"))
+     
+ 
+     state_test = state_get_test_oneshot_impute(version)
+     national_test = national_get_test_oneshot_impute(version)
+ 
+     # Exception handling: no data on nowcast date
+     if (is.null(state_test)) {
+       
+       next
+       
+     }
+           
+     state_test = state_test %>%
+       group_by(geo_value) %>%
+       nest() %>%
+       inner_join(state_selected_models) %>%
+       verify(nrow(.) != 0)
+     
+     national_test = national_test %>%
+     mutate(
+       # Generate predictions with 60% prediction interval
+       preds_60 = {
+         pred_df = as.data.frame(predict(national_selected_models, newdata = national_test, interval = "prediction", level = 0.6))
+         names(pred_df)[names(pred_df) == "lwr"] = "lwr_60"
+         names(pred_df)[names(pred_df) == "upr"] = "upr_60"
+         names(pred_df)[names(pred_df) == "fit"] = "national_fit"
+         pred_df
+       },
+       # Generate predictions with 80% prediction interval
+       preds_80 = {
+         pred_df = as.data.frame(predict(national_selected_models, newdata = national_test, interval = "prediction", level = 0.8))
+         names(pred_df)[names(pred_df) == "lwr"] = "lwr_80"
+         names(pred_df)[names(pred_df) == "upr"] = "upr_80"
+         # No renaming to `state_fit` here as we will discard this fit
+         pred_df
+       }
+     ) %>%
+     unnest(c(preds_60, preds_80)) %>%
+     select(-fit) %>%  # Discarding the duplicate fit from the 80% prediction
+     mutate(resid = abs(national_fit - GT))
+     
+ 
+     state_Tested = state_test %>%
+       mutate(
+         preds_60 = map2(model, data, 
+                         ~{
+                           pred_df <- as.data.frame(predict(.x, newdata = .y, interval = "prediction", level = 0.6))
+                           names(pred_df)[names(pred_df) == "lwr"] <- "lwr_60"
+                           names(pred_df)[names(pred_df) == "upr"] <- "upr_60"
+                           names(pred_df)[names(pred_df) == "fit"] <- "state_fit"
+                           pred_df
+                         }),
+         preds_80 = map2(model, data, 
+                         ~{
+                           pred_df <- as.data.frame(predict(.x, newdata = .y, interval = "prediction", level = 0.8))
+                           names(pred_df)[names(pred_df) == "lwr"] <- "lwr_80"
+                           names(pred_df)[names(pred_df) == "upr"] <- "upr_80"
+                           names(pred_df)[names(pred_df) == "fit"] <- "fit_80"
+                           pred_df
+                         })
+       ) %>%
+       select(-model) %>%
+       unnest(cols = c(preds_60, preds_80, data)) %>%
+       select(-fit_80) %>%
+       mutate(
+         resid = abs(state_fit - GT)
+       )
+     
+     Tested = state_Tested %>%
+       inner_join(national_Tested, by = c("geo_value", "time_value", "issue_date")) %>%
+       inner_join(opt_alpha, by = "geo_value") %>%
+       group_by(geo_value) %>%
+       mutate(mixed_pred = optimal * state_fit + (1 - optimal) * national_fit) %>%
+       mutate(staleness = as.numeric(time_value - omi_start))
+     
+     
+     back_2 = rbind(back_2, Tested)
+     
+   }
+   
+ }
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
Joining with `by = join_by(geo_value)`
